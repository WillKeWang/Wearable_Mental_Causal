{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45539e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Temporal Causal Discovery using DAGitty (Simplified Import)\n",
    "# =========================================================\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "from itertools import product\n",
    "from typing import List, Tuple, Set\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "# Load required R library\n",
    "ro.r('library(dagitty)')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930a340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_edge_list_from_csv(\n",
    "    csv_path: str,\n",
    "    sample_frac: float,\n",
    "    existence_threshold: int = 50,\n",
    "    direction_count_threshold: int = 10,\n",
    "    orientation_threshold: float = 0.85,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Load causal discovery edge results from CSV and return a cleaned edge list.\n",
    "\n",
    "    Args:\n",
    "        csv_path: path to the causal discovery results CSV file.\n",
    "        sample_frac: fraction value to filter (e.g., 0.8).\n",
    "        existence_threshold: minimum total frequency for an edge to be considered.\n",
    "        direction_count_threshold: minimum directional count required to call an edge directed.\n",
    "        orientation_threshold: ratio threshold (e.g., 0.85) to determine direction robustness.\n",
    "\n",
    "    Returns:\n",
    "        A list of (a, b, edge_type) tuples such as ('X', 'Y', '->') or ('X', 'Y', '--').\n",
    "    \"\"\"\n",
    "    # ---------- Step 1: Load and filter ----------\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_filtered = df.loc[df[\"sample_frac\"] == sample_frac].reset_index(drop=True)\n",
    "\n",
    "    # ---------- Step 2: Build dictionary ----------\n",
    "    edge_dict = {\n",
    "        (row[\"from_var\"], row[\"to_var\"]): [int(round(row[\"freq\"] * 100)), row[\"edge_type\"]]\n",
    "        for _, row in df_filtered.iterrows()\n",
    "    }\n",
    "\n",
    "    # ---------- Step 3: Aggregate directions ----------\n",
    "    edge_stat = {}\n",
    "    for (a, b), (freq, typ) in edge_dict.items():\n",
    "        key = tuple(sorted([a, b]))\n",
    "        if key not in edge_stat:\n",
    "            edge_stat[key] = {\"Nab\": 0, \"Nba\": 0, \"Nun\": 0}\n",
    "\n",
    "        if typ == \"directed\":\n",
    "            if (a, b) == key:\n",
    "                edge_stat[key][\"Nab\"] += freq\n",
    "            else:\n",
    "                edge_stat[key][\"Nba\"] += freq\n",
    "        elif typ == \"undirected\":\n",
    "            edge_stat[key][\"Nun\"] += freq\n",
    "\n",
    "    # ---------- Step 4: Build edge list ----------\n",
    "    edge_list = []\n",
    "    for (left, right), stat in edge_stat.items():\n",
    "        Nab = stat[\"Nab\"]\n",
    "        Nba = stat[\"Nba\"]\n",
    "        Nun = stat[\"Nun\"]\n",
    "        total = Nab + Nba + Nun\n",
    "\n",
    "        if total < existence_threshold:\n",
    "            continue\n",
    "\n",
    "        if Nab > Nba:\n",
    "            if Nab >= direction_count_threshold and Nab / (Nab + Nba) >= orientation_threshold:\n",
    "                edge_list.append((left, right, \"->\"))\n",
    "            else:\n",
    "                edge_list.append((left, right, \"--\"))\n",
    "        elif Nba > Nab:\n",
    "            if Nba >= direction_count_threshold and Nba / (Nba + Nab) >= orientation_threshold:\n",
    "                edge_list.append((right, left, \"->\"))\n",
    "            else:\n",
    "                edge_list.append((left, right, \"--\"))\n",
    "        else:\n",
    "            edge_list.append((left, right, \"--\"))\n",
    "\n",
    "    return edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10cf010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1) Graph parsing from edge list ----------\n",
    "def parse_dagitty_graph(edge_list):\n",
    "    \"\"\"\n",
    "    Given an edge_list already in the form of (src, dst, type),\n",
    "    return a set of unique node names and the edge list itself.\n",
    "\n",
    "    Example:\n",
    "        input = [\n",
    "            ('age_binned', 'promis_dep_sum_tm1', '->'),\n",
    "            ('age_binned', 'promis_anx_sum_tm1', '->'),\n",
    "            ('promis_anx_sum_tm1', 'promis_dep_sum_tm1', '--')\n",
    "        ]\n",
    "\n",
    "        output:\n",
    "            nodes = {'age_binned', 'promis_dep_sum_tm1', 'promis_anx_sum_tm1'}\n",
    "            edges = same as input\n",
    "    \"\"\"\n",
    "    nodes: Set[str] = set()\n",
    "    edges: List[Tuple[str, str, str]] = []\n",
    "\n",
    "    for u, v, t in edge_list:\n",
    "        nodes.add(u)\n",
    "        nodes.add(v)\n",
    "        edges.append((u, v, t))\n",
    "\n",
    "    return nodes, edges\n",
    "\n",
    "# ---------- 2) Ancestor computation (ignoring undirected edges) ----------\n",
    "def ancestors_directed_only(edges, query_nodes, include_self=True): \n",
    "    \"\"\"\n",
    "    Find all ancestor nodes of given query nodes using only directed edges.\n",
    "\n",
    "    Args:\n",
    "        edges: list of (src, dst, type) tuples, where type is '->' or '--'.\n",
    "        query_nodes: list or set of nodes for which to find ancestors.\n",
    "        include_self: if True, include the query nodes themselves\n",
    "                      (consistent with DAGitty's behavior).\n",
    "\n",
    "    Returns:\n",
    "        A set of all ancestor nodes that have a directed path\n",
    "        leading to any of the query nodes.\n",
    "    \"\"\"\n",
    "    parents = defaultdict(set)\n",
    "    for src, dst, typ in edges:\n",
    "        if typ == '->':\n",
    "            parents[dst].add(src)\n",
    "\n",
    "    anc: Set[str] = set()\n",
    "    # DAGitty's ancestors() by default includes the node itself.\n",
    "    if include_self:\n",
    "        anc.update(query_nodes)\n",
    "\n",
    "    stack = list(query_nodes)\n",
    "    seen = set(query_nodes)\n",
    "\n",
    "    # Depth-first traversal following parent (reverse) links\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for p in parents.get(cur, set()):\n",
    "            if p not in seen:\n",
    "                seen.add(p)\n",
    "                anc.add(p)\n",
    "                stack.append(p)\n",
    "    return anc\n",
    "\n",
    "# ---------- 3) Edge filtering ----------\n",
    "def filter_edges_by_nodes(edges, keep_nodes):\n",
    "    \"\"\"\n",
    "    Filter the given edge list to include only the edges whose\n",
    "    source and destination nodes are both within a specified set.\n",
    "\n",
    "    Args:\n",
    "        edges: list of (src, dst, type) tuples representing edges in the graph.\n",
    "        keep_nodes: set of node names to keep in the filtered graph.\n",
    "\n",
    "    Returns:\n",
    "        A filtered list of edges where both endpoints belong to keep_nodes.\n",
    "    \"\"\"\n",
    "    return [(u, v, t) for (u, v, t) in edges if u in keep_nodes and v in keep_nodes]\n",
    "\n",
    "# ---------- 4) Cycle and name checking ----------\n",
    "def creates_cycle(adj, u, v) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether adding a directed edge u -> v would create a cycle\n",
    "    in the current directed adjacency structure.\n",
    "\n",
    "    Args:\n",
    "        adj: dict[str, set[str]], representing the current adjacency list\n",
    "             of directed edges (e.g., adj[u] = {v1, v2, ...}).\n",
    "        u: source node of the new edge.\n",
    "        v: destination node of the new edge.\n",
    "\n",
    "    Returns:\n",
    "        True if adding u -> v would introduce a cycle (i.e., if a path\n",
    "        already exists from v back to u), otherwise False.\n",
    "    \"\"\"\n",
    "    if u == v:\n",
    "        return True\n",
    "    visited = set()\n",
    "    dq = deque([v])\n",
    "    while dq:\n",
    "        x = dq.popleft()\n",
    "        if x == u:\n",
    "            return True\n",
    "        for w in adj.get(x, ()):\n",
    "            if w not in visited:\n",
    "                visited.add(w)\n",
    "                dq.append(w)\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_temporal(name: str) -> bool:\n",
    "    return name.endswith('_t') or name.endswith('_tm1')\n",
    "\n",
    "# ---------- 5) Orientation rules for undirected edges ----------\n",
    "def orient_pdag_to_dag_all(edges):\n",
    "    \"\"\"\n",
    "    Generate all possible DAG completions from a given PDAG\n",
    "    by orienting each undirected edge ('--') in both possible directions.\n",
    "\n",
    "    Each resulting DAG must satisfy two constraints:\n",
    "        1. No directed cycles are introduced.\n",
    "        2. The destination node (outcome) must be temporally valid,\n",
    "           i.e., its name must end with '_t' or '_tm1'.\n",
    "\n",
    "    Args:\n",
    "        edges: list of (src, dst, type) tuples representing the PDAG.\n",
    "               'type' can be '->' (directed) or '--' (undirected).\n",
    "\n",
    "    Returns:\n",
    "        A list of DAGs, where each DAG is represented as a list of (src, dst)\n",
    "        directed edges that form a valid acyclic graph.\n",
    "\n",
    "    Notes:\n",
    "        - For each undirected edge (u, v), both orientations (u→v and v→u)\n",
    "          are tested independently.\n",
    "        - Only combinations that pass all constraints (no cycles, valid\n",
    "          temporal naming) are included in the final result.\n",
    "    \"\"\"\n",
    "    directed = [(u, v) for (u, v, t) in edges if t == '->']\n",
    "    undirected = [(u, v) for (u, v, t) in edges if t == '--']\n",
    "\n",
    "    all_dags = []\n",
    "    for bits in product([0, 1], repeat=len(undirected)):\n",
    "        adj = defaultdict(set)\n",
    "        # Add existing directed edges first\n",
    "        for u, v in directed:\n",
    "            adj[u].add(v)\n",
    "        dir_edges = directed.copy()\n",
    "\n",
    "        ok = True\n",
    "        for (u, v), bit in zip(undirected, bits):\n",
    "            # bit=0 → u→v, bit=1 → v→u\n",
    "            src, dst = (u, v) if bit == 0 else (v, u)\n",
    "\n",
    "            # Temporal constraint: only variables ending with '_t' or '_tm1'\n",
    "            # can appear as outcome (destination) nodes.\n",
    "            if not is_temporal(dst):\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            # Cycle check\n",
    "            if creates_cycle(adj, src, dst):\n",
    "                ok = False\n",
    "                break\n",
    "\n",
    "            # Add the directed edge\n",
    "            adj[src].add(dst)\n",
    "            dir_edges.append((src, dst))\n",
    "\n",
    "        if ok:\n",
    "            all_dags.append(dir_edges)\n",
    "\n",
    "    return all_dags\n",
    "\n",
    "# ---------- 6) Build DAGitty-compatible graph string ----------\n",
    "def build_dagitty_dag_string(nodes, directed_edges):\n",
    "    \"\"\"\n",
    "    Construct a DAGitty-compatible DAG string representation from\n",
    "    a given set of nodes and directed edges.\n",
    "\n",
    "    Args:\n",
    "        nodes: set of node names (strings) to include in the DAG.\n",
    "        directed_edges: list of (src, dst) tuples representing directed edges.\n",
    "\n",
    "    Returns:\n",
    "        A formatted string defining the DAG in DAGitty syntax, e.g.:\n",
    "\n",
    "            dag {\n",
    "                A\n",
    "                B\n",
    "                C\n",
    "                A -> B ;\n",
    "                B -> C ;\n",
    "            }\n",
    "\n",
    "    Notes:\n",
    "        - Each node is printed on a new line (sorted alphabetically).\n",
    "        - Each directed edge is represented as 'A -> B ;' on a single line.\n",
    "        - The output can be directly parsed by the R `dagitty` package.\n",
    "    \"\"\"\n",
    "    node_lines = \"\\n\".join(sorted(nodes))\n",
    "    edge_lines = \" \".join(f\"{u} -> {v} ;\" for (u, v) in directed_edges)\n",
    "    return f\"dag {{\\n{node_lines}\\n{edge_lines}\\n}}\"\n",
    "\n",
    "# ---------- 7) Compute adjustment sets for a single DAG ----------\n",
    "def adjustment_sets_for_dag(nodes, directed_edges, treatment, outcome):\n",
    "    \"\"\"\n",
    "    Compute minimal adjustment sets for a single DAG using the R 'dagitty' package.\n",
    "\n",
    "    Args:\n",
    "        nodes: set of node names (strings).\n",
    "        directed_edges: list of (src, dst) tuples representing directed edges.\n",
    "        treatment: name of the treatment variable.\n",
    "        outcome: name of the outcome variable.\n",
    "\n",
    "    Returns:\n",
    "        dag_str: DAGitty-compatible DAG string.\n",
    "        py_sets: list of adjustment sets (each set represented as a list of variable names).\n",
    "                 Example: [] represents an empty adjustment set {}.\n",
    "        min_size: size (int) of the smallest minimal adjustment set,\n",
    "                  or None if no adjustment set exists.\n",
    "\n",
    "    Notes:\n",
    "        - The function constructs the DAG in DAGitty syntax, passes it to R via `rpy2`,\n",
    "          and retrieves the minimal adjustment sets using `adjustmentSets()`.\n",
    "        - DAGitty may return multiple valid minimal adjustment sets; all are included.\n",
    "    \"\"\"\n",
    "    dag_str = build_dagitty_dag_string(nodes, directed_edges)\n",
    "    g = ro.r['dagitty'](dag_str)\n",
    "    adj = ro.r['adjustmentSets'](g, treatment=treatment, outcome=outcome, type=\"minimal\")\n",
    "\n",
    "    # Each element in 'adj' is an R character vector (possibly empty)\n",
    "    py_sets = [list(s) for s in adj]  # [] == {} → empty adjustment set\n",
    "    min_size = min((len(s) for s in py_sets), default=None)\n",
    "    return dag_str, py_sets, min_size\n",
    "\n",
    "\n",
    "# ---------- 8) Evaluate all possible DAG completions ----------\n",
    "def evaluate_all_dags(dag_edge_sets, nodes, treatment, outcome):\n",
    "    \"\"\"\n",
    "    Compute adjustment sets across all DAG completions derived from a PDAG.\n",
    "\n",
    "    Args:\n",
    "        dag_edge_sets: list of DAGs, where each DAG is represented as a list of (src, dst) edges.\n",
    "        nodes: set of all node names (strings).\n",
    "        treatment: name of the treatment variable.\n",
    "        outcome: name of the outcome variable.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, one per DAG, each containing:\n",
    "            - \"idx\": DAG index number.\n",
    "            - \"edges\": list of directed edges used in this DAG.\n",
    "            - \"dag_str\": the DAGitty string representation.\n",
    "            - \"adj_sets\": list of minimal adjustment sets (possibly empty).\n",
    "            - \"min_size\": size of the smallest minimal adjustment set.\n",
    "            - \"has_sets\": boolean indicating whether any adjustment set exists.\n",
    "\n",
    "    Notes:\n",
    "        - This function iterates through all possible DAG completions (e.g., generated by\n",
    "          `orient_pdag_to_dag_all()`), computes adjustment sets for each, and aggregates results.\n",
    "        - It is useful for exploring the impact of undirected edge orientations on causal adjustment.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, dir_edges in enumerate(dag_edge_sets):\n",
    "        dag_str, sets_i, min_size = adjustment_sets_for_dag(nodes, dir_edges, treatment, outcome)\n",
    "        results.append({\n",
    "            \"idx\": i,\n",
    "            \"edges\": dir_edges,\n",
    "            \"dag_str\": dag_str,\n",
    "            \"adj_sets\": sets_i,     # [[], ['a','b'], ...]\n",
    "            \"min_size\": min_size,   # None (no set) or int\n",
    "            \"has_sets\": len(sets_i) > 0\n",
    "        })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8b368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = extract_edge_list_from_csv(\n",
    "    csv_path=\"causal_discovery_results/all_edges_sample_frac_with_vars.csv\",\n",
    "    sample_frac=0.8,\n",
    "    existence_threshold=50,\n",
    "    direction_count_threshold=10,\n",
    "    orientation_threshold=0.85,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b511820",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = parse_dagitty_graph(edge_list)\n",
    "treatment = \"promis_dep_sum_t\"\n",
    "outcome  = \"rem_std_t\"\n",
    "anc_nodes = ancestors_directed_only(edge_list, [treatment, outcome], include_self=True)\n",
    "sub_edges = filter_edges_by_nodes(edge_list, anc_nodes)\n",
    "dag_edge_sets = orient_pdag_to_dag_all(sub_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c8e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_all_dags(dag_edge_sets, anc_nodes, treatment, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ae0e811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'idx': 0,\n",
       "  'edges': [('age_binned', 'promis_dep_sum_tm1'),\n",
       "   ('age_binned', 'promis_anx_sum_tm1'),\n",
       "   ('age_binned', 'rmssd_std_tm1'),\n",
       "   ('sex_encoded', 'promis_anx_sum_tm1'),\n",
       "   ('promis_dep_sum_tm1', 'promis_dep_sum_t'),\n",
       "   ('promis_anx_sum_tm1', 'promis_dep_sum_t'),\n",
       "   ('rmssd_std_tm1', 'rem_std_t'),\n",
       "   ('rem_mean_tm1', 'rem_std_t'),\n",
       "   ('rem_std_tm1', 'rem_std_t'),\n",
       "   ('temperature_max_mean_tm1', 'rem_mean_tm1'),\n",
       "   ('promis_dep_sum_t', 'rem_std_t'),\n",
       "   ('promis_anx_sum_tm1', 'promis_dep_sum_tm1')],\n",
       "  'dag_str': 'dag {\\nage_binned\\npromis_anx_sum_tm1\\npromis_dep_sum_t\\npromis_dep_sum_tm1\\nrem_mean_tm1\\nrem_std_t\\nrem_std_tm1\\nrmssd_std_tm1\\nsex_encoded\\ntemperature_max_mean_tm1\\nage_binned -> promis_dep_sum_tm1 ; age_binned -> promis_anx_sum_tm1 ; age_binned -> rmssd_std_tm1 ; sex_encoded -> promis_anx_sum_tm1 ; promis_dep_sum_tm1 -> promis_dep_sum_t ; promis_anx_sum_tm1 -> promis_dep_sum_t ; rmssd_std_tm1 -> rem_std_t ; rem_mean_tm1 -> rem_std_t ; rem_std_tm1 -> rem_std_t ; temperature_max_mean_tm1 -> rem_mean_tm1 ; promis_dep_sum_t -> rem_std_t ; promis_anx_sum_tm1 -> promis_dep_sum_tm1 ;\\n}',\n",
       "  'adj_sets': [['rmssd_std_tm1'],\n",
       "   ['age_binned'],\n",
       "   ['promis_anx_sum_tm1', 'promis_dep_sum_tm1']],\n",
       "  'min_size': 1,\n",
       "  'has_sets': True},\n",
       " {'idx': 1,\n",
       "  'edges': [('age_binned', 'promis_dep_sum_tm1'),\n",
       "   ('age_binned', 'promis_anx_sum_tm1'),\n",
       "   ('age_binned', 'rmssd_std_tm1'),\n",
       "   ('sex_encoded', 'promis_anx_sum_tm1'),\n",
       "   ('promis_dep_sum_tm1', 'promis_dep_sum_t'),\n",
       "   ('promis_anx_sum_tm1', 'promis_dep_sum_t'),\n",
       "   ('rmssd_std_tm1', 'rem_std_t'),\n",
       "   ('rem_mean_tm1', 'rem_std_t'),\n",
       "   ('rem_std_tm1', 'rem_std_t'),\n",
       "   ('temperature_max_mean_tm1', 'rem_mean_tm1'),\n",
       "   ('promis_dep_sum_t', 'rem_std_t'),\n",
       "   ('promis_dep_sum_tm1', 'promis_anx_sum_tm1')],\n",
       "  'dag_str': 'dag {\\nage_binned\\npromis_anx_sum_tm1\\npromis_dep_sum_t\\npromis_dep_sum_tm1\\nrem_mean_tm1\\nrem_std_t\\nrem_std_tm1\\nrmssd_std_tm1\\nsex_encoded\\ntemperature_max_mean_tm1\\nage_binned -> promis_dep_sum_tm1 ; age_binned -> promis_anx_sum_tm1 ; age_binned -> rmssd_std_tm1 ; sex_encoded -> promis_anx_sum_tm1 ; promis_dep_sum_tm1 -> promis_dep_sum_t ; promis_anx_sum_tm1 -> promis_dep_sum_t ; rmssd_std_tm1 -> rem_std_t ; rem_mean_tm1 -> rem_std_t ; rem_std_tm1 -> rem_std_t ; temperature_max_mean_tm1 -> rem_mean_tm1 ; promis_dep_sum_t -> rem_std_t ; promis_dep_sum_tm1 -> promis_anx_sum_tm1 ;\\n}',\n",
       "  'adj_sets': [['rmssd_std_tm1'],\n",
       "   ['age_binned'],\n",
       "   ['promis_anx_sum_tm1', 'promis_dep_sum_tm1']],\n",
       "  'min_size': 1,\n",
       "  'has_sets': True}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43beca4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
